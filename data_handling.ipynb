{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "stopwords = stopwords.words(\"english\")\n",
    "\n",
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting en-core-web-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from en-core-web-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/keddie/anaconda3/envs/interview/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "Updated Git hooks.\n",
      "Git LFS initialized.\n",
      "The data were already unpacked\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "path_data = \"Data/\"\n",
    "!python -m spacy download en_core_web_sm\n",
    "lemmatizer = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "!bash downloads.bash $path_data $model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special case: if the label does not contain \"P\" at the start (due to possible errors - or just missing in the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘Processed/’: File exists\n",
      "mkdir: cannot create directory ‘Processed/’: File exists\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def get_text_from_xml(xml_file: str, data_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtain a dataset of articles from a given XML file path\n",
    "    \"\"\"\n",
    "    parsed_dir = ET.parse(path_data + xml_file)\n",
    "    parsed_dir = parsed_dir.getroot()\n",
    "\n",
    "    data = {\"ID\": [], \"Text\": []}\n",
    "    for child_node in parsed_dir:\n",
    "        id = child_node.attrib[\"id\"]\n",
    "        if \"P\" != id[0] and id[0] != \"A\":\n",
    "            id = \"P\" + id\n",
    "        data[\"ID\"].append(id)\n",
    "        data[\"Text\"].append(child_node.text)\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    transformer_data = data.copy()\n",
    "\n",
    "    !mkdir \"Processed/\"\n",
    "    \n",
    "    transformer_data[\"Text\"] = transformer_data[\"Text\"].apply(data_preprocessing_transformer)\n",
    "    transformer_data.to_pickle(\"Processed/\" + \"transformer_\" + data_file)\n",
    "\n",
    "    data[\"Text\"] = data[\"Text\"].apply(data_preprocessing)\n",
    "    data.to_pickle(\"Processed/\" + data_file)\n",
    "\n",
    "    return data\n",
    "\n",
    "def data_preprocessing_transformer(data: str) -> list:\n",
    "    \"\"\"\n",
    "    Minimal preprocessing for transformers. This includes:\n",
    "    * lowercasing\n",
    "    * replacement of all whitespace characters with \" \"\n",
    "    * and removing any surplus \" \" characters\n",
    "    * tokenization based on single \" \"\n",
    "    \"\"\"\n",
    "    data = data.lower()\n",
    "    data = re.sub(r\"\\s+\", \" \", data)\n",
    "    data = data.strip()\n",
    "    return data.split(\" \")\n",
    "\n",
    "def data_preprocessing(data: str) -> list:\n",
    "    \"\"\"\n",
    "    Main preprocessing pipeline. Tokenize a given sentence such that:\n",
    "    * all tokens are lower-cased\n",
    "    * compound nouns are kept (e.g. hand-arm)\n",
    "    * the tokens are lemmatized\n",
    "    * any stop words, isolated punctuation, and tokens with numeric characters are removed\n",
    "    \"\"\"\n",
    "    data = data.lower()\n",
    "    # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ from string.punctuation\n",
    "    # keep compund nouns\n",
    "    data = regexp_tokenize(data, r\"[\\w]+(?:[!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~][\\w]+[()*[\\]{}]?){1,}|[\\w]+|(?:[([{]\\w+[)\\]}])+\")\n",
    "\n",
    "    # lemmatize\n",
    "    aux_data = data\n",
    "    data = \" \".join(data)\n",
    "    lemmatized_data = lemmatizer(data)\n",
    "    data = [token.lemma_ for token in lemmatized_data]\n",
    "\n",
    "    # remove all punctuation\n",
    "    data = [word for word in data if len(word) > 1]\n",
    "\n",
    "    # some of the compound-nouns are separated by the lemmatizer, as such it is necessary to readd those tokens \n",
    "    # back as they were, but still in their lemmatized forms\n",
    "    aux = []\n",
    "    for aux_token in aux_data:\n",
    "        found = False\n",
    "        for token in lemmatized_data:\n",
    "            if token.text == aux_token:\n",
    "                aux.append(token.lemma_)\n",
    "                found = True\n",
    "            if found:\n",
    "                break\n",
    "        if not found:\n",
    "            aux.append(aux_token)\n",
    "    data = aux\n",
    "\n",
    "    # remove stop words, any remaining punctuation, and tokens containing digits\n",
    "    data = [word for word in data if word not in stopwords and word not in string.punctuation and not re.search(r\"[0-9]+\", word)]\n",
    "\n",
    "    return data\n",
    "\n",
    "directive_data = get_text_from_xml(\"DIR_EN_32002L0044.xml\", \"directive_data.pickle\")\n",
    "provision_data = get_text_from_xml(\"NIM_EN.xml\", \"provision_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directive individual directive within meaning article directive lay minimum requirement protection worker risk health safety arise likely arise exposure mechanical vibration\n",
      "this directive, which is the 16th individual directive within the meaning of article 16(1) of directive 89/391/eec, lays down minimum requirements for the protection of workers from risks to their health and safety arising or likely to arise from exposure to mechanical vibration.\n"
     ]
    }
   ],
   "source": [
    "text_transformer = pd.read_pickle(\"Processed/transformer_directive_data.pickle\")[\"Text\"]\n",
    "text_processed = pd.read_pickle(\"Processed/directive_data.pickle\")[\"Text\"]\n",
    "\n",
    "print(\" \".join(text_processed.iloc[0]))\n",
    "print(\" \".join(text_transformer.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'without prejudice to sections 9 and 10 of the act, where employees are exposed to risk from mechanical vibration, an employer shall provide those employees or their safety representative (or both) with suitable and sufficient information, instruction and training, including - the technical and organisational measures taken in order to comply with these regulations, the exposure limit values and the exposure action values, the results of the risk assessment and measurement of the mechanical vibration carried out in accordance with regulation 5 and the potential injury arising from the work equipment in use, why and how to detect and report signs of injury, the circumstances in which health surveillance is made available to employees and its purpose, in accordance with regulation 8, and safe working practices to minimise exposure to mechanical vibration.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(pd.read_pickle(\"Processed/transformer_provision_data.pickle\")[\"Text\"].iloc[15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
